{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DjangoCODEFLOW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBjz9yJ8Dbfe"
      },
      "source": [
        "#Libraries\n",
        "from typing import Optional, Any\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from tifffile import TiffFile, TiffWriter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "from sklearn  import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from joblib import dump, load\n",
        "from skimage.filters import threshold_otsu\n",
        "from skimage.segmentation import clear_border\n",
        "from skimage.measure import label, regionprops\n",
        "from skimage.morphology import closing, square\n",
        "# Import the function for reading an image\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2yiq\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "import h5py\n",
        "\n",
        "import cv2\n",
        "from skimage.exposure import equalize_hist\n",
        "from matplotlib import pyplot\n",
        "from matplotlib import colors as cls\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.neighbors import (NeighborhoodComponentsAnalysis, KNeighborsClassifier)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import RadiusNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.feature_selection import VarianceThreshold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import os \n",
        "\n",
        "#LIBRARIS USED IN VIEWs FILE DJango\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from django.core.files import File\n",
        "import os\n",
        "from django.conf import settings\n",
        "from django.shortcuts import render\n",
        "from django.http import HttpResponse\n",
        "from django.shortcuts import render\n",
        "from django.views.generic import TemplateView\n",
        "from django.views import View\n",
        "from django.http import JsonResponse\n",
        "import json\n",
        "from typing import Optional, Any\n",
        "import warnings\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "from tifffile import TiffFile, TiffWriter\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import NearestCentroid\n",
        "from joblib import dump, load\n",
        "from skimage.measure import label, regionprops\n",
        "# Import the function for reading an image\n",
        "from skimage.io import imread\n",
        "from skimage.color import rgb2yiq\n",
        "from skimage.color import rgb2gray\n",
        "\n",
        "\n",
        "# import cv2\n",
        "from skimage.exposure import equalize_hist\n",
        "from matplotlib import pyplot\n",
        "from matplotlib import colors as cls\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from .models import *\n",
        "\n",
        "from . import corefiles\n",
        "import h5py\n",
        "from classifierapp.dataset.extractdataset import loadDataset\n",
        "from .corefiles import read_mtiff,read_stiff\n",
        "from tifffile import TiffFile, TiffWriter\n",
        "from classifierapp.models_fold.getmodel import loadModel\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV8uSiyJJf9v"
      },
      "source": [
        "Load MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua7FX_q3JfuR"
      },
      "source": [
        "\n",
        "def loadModel():\n",
        "    __location__ = os.path.realpath(\n",
        "    os.path.join(os.getcwd(), os.path.dirname(__file__)))\n",
        "\n",
        "    return  load(os.path.join(__location__,'kbest35_mlp10000logisticmodel.joblib')) , load(os.path.join(__location__,'kbest35_n10000slectkb.joblib'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHTothkoJwg5"
      },
      "source": [
        "# LOAD DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmOcIiTMJw5_"
      },
      "source": [
        "\n",
        "def loadDataset():\n",
        "    __location__ = os.path.realpath(\n",
        "    os.path.join(os.getcwd(), os.path.dirname(__file__)))\n",
        "\n",
        "    # hf = h5py.File( os.path.join(__location__, 'data.h5'), 'r')\n",
        "    # hf.keys()\n",
        "    # # extract features\n",
        "    # features = hf.get('features')\n",
        "    # labels = hf.get('labels')\n",
        "    # features = np.array(features)\n",
        "    # labels = np.array(labels)\n",
        "    # return features,labels\n",
        "\n",
        "    hf = h5py.File( os.path.join(__location__, 'kbest35_mlp10000_datasetlogistic.h5'), 'r')\n",
        "    # extract features\n",
        "    X_train = hf.get('trainx')\n",
        "    y_train = hf.get('trainy')\n",
        "    X_test = hf.get('testx')\n",
        "    y_test = hf.get('testy')\n",
        "    X_train = np.array(X_train)\n",
        "    y_train = np.array(y_train)\n",
        "    X_test = np.array(X_test)\n",
        "    y_test = np.array(y_test)\n",
        "    return X_train,y_train,X_test,y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NT0MdDvTKPzE"
      },
      "source": [
        "#  Prediction Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "St_1KtWeKQBv"
      },
      "source": [
        "def predictFunction(modelobj,selectorKb,new_img,spim):\n",
        "  \n",
        "  print(new_img.shape)\n",
        "  xtest1=selectorKb.transform(new_img)\n",
        "  print(xtest1.shape)\n",
        "  prediction=modelobj.predict(xtest1)\n",
        "  prediction=prediction.astype(int)\n",
        "  print(\"prediction shpare\",prediction.shape)\n",
        "  unique_labels_testingimage=np.unique(prediction)\n",
        "  label_img = np.reshape(prediction, (spim.shape[0], spim.shape[1]))\n",
        "  label_img.shape\n",
        "  return label_img,prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1U9lwMMuKKwx"
      },
      "source": [
        "Visualization Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu5GN_KbKK9W"
      },
      "source": [
        "\n",
        "def displayClassifiedImage(spim,colorimg,new_img,label_img):\n",
        "    '''\n",
        "    This function takes the predicted labels and the image to be classified, \n",
        "    and adds colors to it pixel by pixel. \n",
        "    ''' \n",
        "    image=spim[:,:,0]\n",
        "    thresholded_image = image > 0.1\n",
        "   \n",
        "\n",
        "\n",
        "    label_image = label(thresholded_image)\n",
        "    props = regionprops(label_image)\n",
        "    # red,gray,green,black,purple,blue,yellow,aqua,brown,magenta,orange\n",
        "    color_dict={0:[255,0,0],1:[128,128,128],2:[0,128,0],3:[0,0,0],4:[128,0,128],5:[0,0,255],6:[255,255,0],7:[0,100,100],\n",
        "                8:[165,42,42],9:[255,0,255],10:[255,165,0]}\n",
        "    for p in props:\n",
        "        region_coords=p.coords\n",
        "        for pixelcoord in  region_coords:\n",
        "            colorimg[pixelcoord[1],pixelcoord[0]]=color_dict[label_img[pixelcoord[1],pixelcoord[0]]]\n",
        "        \n",
        "    return colorimg     \n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGGyksRiKwaE"
      },
      "source": [
        "# READ STIFF AND READMTIFF Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOoARgImK0bA"
      },
      "source": [
        "def read_mtiff(filename):\n",
        "    \"\"\"\n",
        "    Read a mask bitmap tiff.\n",
        "\n",
        "    Mask bitmap tiff contains multiple pages of bitmap masks. The mask label\n",
        "    is stored in tag 65001 in each page. The mask label is stored as an ASCII\n",
        "    string that may contain unicode codepoints encoded as ASCII character\n",
        "    sequences (see unicode-esca                                                         pe encoding in Python docs).\n",
        "\n",
        "    :param filename:    filename of the mask tiff to read.\n",
        "    :return:            Dict[label: str, mask: ndarray], where\n",
        "                        label: the mask label\n",
        "                        mask: the boolean bitmap associated with the label.\n",
        "    \"\"\"\n",
        "    TIFFTAG_MASK_LABEL = 65001\n",
        "    masks = dict()\n",
        "    with TiffFile(filename) as tiff:\n",
        "        for p in range(0, len(tiff.pages)):\n",
        "            label_tag = tiff.pages[p].tags.get(TIFFTAG_MASK_LABEL)\n",
        "            if label_tag is None:\n",
        "                if p > 0:\n",
        "                    print(f'** page {p}: no TIFF_MASK_LABEL tag. Ignored.')\n",
        "                continue\n",
        "            label = label_tag.value.encode('ascii').decode('unicode-escape')\n",
        "            mask = tiff.asarray(key=p)\n",
        "            masks[label] = mask > 0\n",
        "    return masks\n",
        "\n",
        "def read_stiff(filename: str, silent=False, rgb_only=False):\n",
        "    \"\"\"\n",
        "    :param filename:    filename of the spectral tiff to read.\n",
        "    :return:            Tuple[spim, wavelengths, rgb, metadata], where\n",
        "                        spim: spectral image cube of form [height, width, bands],\n",
        "                        wavelengths: the center wavelengths of the bands,\n",
        "                        rgb: a color render of the spectral image [height, width, channels] or None\n",
        "                        metadata: a free-form metadata string stored in the image, or an empty string\n",
        "    \"\"\"\n",
        "    TIFFTAG_WAVELENGTHS = 65000\n",
        "    TIFFTAG_METADATA = 65111\n",
        "    spim = None\n",
        "    wavelengths = None\n",
        "    rgb = None\n",
        "    metadata = None\n",
        "\n",
        "    first_band_page = 0\n",
        "    with TiffFile(filename) as tiff:\n",
        "        # The RGB image is optional, the first band image maybe on the first page:\n",
        "        first_band_page = 0\n",
        "        if tiff.pages[first_band_page].ndim == 3:\n",
        "            rgb = tiff.pages[0].asarray()\n",
        "            # Ok, the first band image is on the second page\n",
        "            first_band_page = first_band_page + 1\n",
        "\n",
        "        multiple_wavelength_lists = False\n",
        "        multiple_metadata_fields = False\n",
        "        for band_page in range(first_band_page, len(tiff.pages)):\n",
        "            # The wavelength list is supposed to be on the first band image.\n",
        "            # The older write_tiff writes it on all pages, though, so make\n",
        "            # a note of it.\n",
        "            tag = tiff.pages[band_page].tags.get(TIFFTAG_WAVELENGTHS)\n",
        "            tag_value = tag.value if tag else tuple()\n",
        "            if tag_value:\n",
        "                if wavelengths is None:\n",
        "                    wavelengths = tag_value\n",
        "                elif wavelengths == tag_value:\n",
        "                    multiple_wavelength_lists = True\n",
        "                elif wavelengths != tag_value:\n",
        "                    # Well, the image is just broken then?\n",
        "                    raise RuntimeError(f'Spectral-Tiff \"{filename}\" contains multiple differing wavelength lists!')\n",
        "\n",
        "            # The metadata string, like the wavelength list, is supposed to be\n",
        "            # on the first band image. The older write_tiff wrote it on all\n",
        "            # pages, too. Make a note of it.\n",
        "            tag = tiff.pages[band_page].tags.get(TIFFTAG_METADATA)\n",
        "            tag_value = tag.value if tag else ''\n",
        "            if tag_value:\n",
        "                if metadata is None:\n",
        "                    metadata = tag_value\n",
        "                elif metadata == tag_value:\n",
        "                    multiple_metadata_fields = True\n",
        "                elif metadata != tag_value:\n",
        "                    # Well, for some reason there are multiple metadata fields\n",
        "                    # with varying content. This version of the function does\n",
        "                    # not care for such fancyness.\n",
        "                    raise RuntimeError(f'Spectral-Tiff \"{filename}\" contains multiple differing metadata fields!')\n",
        "\n",
        "        # The metadata is stored in an ASCII string. It may contain back-slashed\n",
        "        # hex sequences (unicode codepoints presented as ASCII text). Convert\n",
        "        # ASCII string back to bytes and decode as unicode sequence.\n",
        "        if metadata:\n",
        "            metadata = metadata.encode('ascii').decode('unicode-escape')\n",
        "        else:\n",
        "            metadata = ''\n",
        "\n",
        "        # Some of the early images may have errorneus metadata string.\n",
        "        # Attempt to fix it:\n",
        "        if len(metadata) >= 2 and metadata[0] == \"'\" and metadata[-1] == \"'\":\n",
        "            while metadata[0] == \"'\":\n",
        "                metadata = metadata[1:]\n",
        "            while metadata[-1] == \"'\":\n",
        "                metadata = metadata[:-1]\n",
        "            if '\\\\n' in metadata:\n",
        "                metadata = metadata.replace('\\\\n', '\\n')\n",
        "\n",
        "        # Generate a fake wavelength list, if the spectral tiff has managed to\n",
        "        # lose its own wavelength list.\n",
        "        if not wavelengths:\n",
        "            wavelengths = range(0, len(tiff.pages) - 1 if rgb is not None else len(tiff.pages))\n",
        "\n",
        "        if multiple_wavelength_lists and not silent:\n",
        "            warnings.warn(f'Spectral-Tiff \"{filename}\" contains duplicated wavelength lists!')\n",
        "        if multiple_metadata_fields and not silent:\n",
        "            warnings.warn(f'Spectral-Tiff \"{filename}\" contains duplicated metadata fields!')\n",
        "\n",
        "        if not rgb_only:\n",
        "            spim = tiff.asarray(key=range(first_band_page, len(tiff.pages)))\n",
        "            spim = np.transpose(spim, (1, 2, 0))\n",
        "        else:\n",
        "            spim = None\n",
        "\n",
        "        # Make sure the wavelengths are in an ascending order:\n",
        "        if wavelengths[0] > wavelengths[-1]:\n",
        "            spim = spim[:, :, ::-1] if spim is not None else None\n",
        "            wavelengths = wavelengths[::-1]\n",
        "\n",
        "    # Convert uint16 cube back to float32 cube\n",
        "    if spim is not None and spim.dtype == 'uint16':\n",
        "        spim = spim.astype('float32') / (2**16 - 1)\n",
        "\n",
        "    return spim, np.array(wavelengths), rgb, metadata\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXSCxuTKX2R"
      },
      "source": [
        "MAIN FUNCtion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahydcd_OKYDg"
      },
      "source": [
        "def main():\n",
        "        # get the dataset\n",
        "        X_train,y_train,X_test,y_test=loadDataset()\n",
        "        # get the model \n",
        "        clf,selectorKb=loadModel()\n",
        "        # # Pre process predict image\n",
        "        spim, wl, colorimg, meta=read_stiff(current_image_loaded.tiff_img)  \n",
        "        new_img = spim.reshape((spim.shape[0]*spim.shape[1]), spim.shape[2]) # (H*W,b)\n",
        "        \n",
        "        # # apply prediction \n",
        "        label_img,prediction=predictFunction(clf,selectorKb,new_img,spim)\n",
        "        # Perform Classification and get Image\n",
        "        colorimg=displayClassifiedImage(spim,colorimg,new_img,label_img)\n",
        "        fig, ax = plt.subplots(figsize=(10, 10))\n",
        "        ax.imshow(colorimg)\n",
        "        # Save Classified image\n",
        "        imgfolderpath=settings.MEDIA_ROOT+\"\\\\img\\\\\"+\"classifiedImg.png\"\n",
        "        plt.savefig(imgfolderpath)\n",
        "        current_image_loaded.classified_img='img'+'/classifiedImg.png'\n",
        "        current_image_loaded.save()\n",
        "\n",
        "            # SAVE Threshold image \n",
        "        image=spim[:,:,0]\n",
        "        thresholded_image = image > 0.1\n",
        "        # fig, axs = plt.subplots(nrows=1, ncols=1)\n",
        "        # axs.imshow(thresholded_image,'gray')\n",
        "        # plt.show()\n",
        "        imgfolderpath=settings.MEDIA_ROOT+\"\\\\img\\\\\"+\"thresimg.png\"\n",
        "        plt.savefig(imgfolderpath)\n",
        "        current_image_loaded.thres_img='img'+'/thresimg.png'\n",
        "        current_image_loaded.save()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}