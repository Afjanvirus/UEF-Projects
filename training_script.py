# -*- coding: utf-8 -*-
"""Training_Script.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ySnhmiNA54DQMrfsxAvWqRhETf0bmLkk
"""

#Libraries
from typing import Optional, Any
import warnings
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from tifffile import TiffFile, TiffWriter
import numpy as np
import pandas as pd
import os
from google.colab import drive
from sklearn  import tree
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import NearestCentroid
from joblib import dump, load
from skimage.filters import threshold_otsu
from skimage.segmentation import clear_border
from skimage.measure import label, regionprops
from skimage.morphology import closing, square
# Import the function for reading an image
from skimage.io import imread
from skimage.color import rgb2yiq
from skimage.color import rgb2gray
from sklearn.preprocessing import label_binarize

import h5py

import cv2
from skimage.exposure import equalize_hist
from matplotlib import pyplot
from matplotlib import colors as cls

import numpy as np

from sklearn.decomposition import PCA
from sklearn.pipeline import make_pipeline
from sklearn.neighbors import (NeighborhoodComponentsAnalysis, KNeighborsClassifier)
from sklearn.model_selection import cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import RadiusNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.model_selection import ShuffleSplit
from sklearn.model_selection import StratifiedShuffleSplit

import tensorflow as tf

from sklearn.feature_selection import VarianceThreshold
from sklearn.linear_model import LogisticRegression
from sklearn import svm
from sklearn.metrics import roc_curve, auc
from sklearn.cluster import KMeans

from sklearn.metrics import plot_confusion_matrix
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import roc_curve
from sklearn.metrics import roc_auc_score
import h5py
from sklearn.neural_network import MLPClassifier
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import chi2
import matplotlib.patches as mpatches
from skimage.measure import label, regionprops
# Mounting drive for reflectance images
# drive.mount('/content/drive')

#Reference
#https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html 
#https://datascience.stackexchange.com/questions/28493/confusion-matrix-get-items-fp-fn-tp-tn-python/28502

#https://stackoverflow.com/questions/32838802/numpy-with-python-convert-3d-array-to-2d

"""# READSTIFF AND READMTIFF FUNCTIONS"""

def read_mtiff(filename):
    """
    Read a mask bitmap tiff.

    Mask bitmap tiff contains multiple pages of bitmap masks. The mask label
    is stored in tag 65001 in each page. The mask label is stored as an ASCII
    string that may contain unicode codepoints encoded as ASCII character
    sequences (see unicode-esca                                                         pe encoding in Python docs).

    :param filename:    filename of the mask tiff to read.
    :return:            Dict[label: str, mask: ndarray], where
                        label: the mask label
                        mask: the boolean bitmap associated with the label.
    """
    TIFFTAG_MASK_LABEL = 65001
    masks = dict()
    with TiffFile(filename) as tiff:
        for p in range(0, len(tiff.pages)):
            label_tag = tiff.pages[p].tags.get(TIFFTAG_MASK_LABEL)
            if label_tag is None:
                if p > 0:
                    print(f'** page {p}: no TIFF_MASK_LABEL tag. Ignored.')
                continue
            label = label_tag.value.encode('ascii').decode('unicode-escape')
            mask = tiff.asarray(key=p)
            masks[label] = mask > 0
    return masks

def read_stiff(filename: str, silent=False, rgb_only=False):
    """
    :param filename:    filename of the spectral tiff to read.
    :return:            Tuple[spim, wavelengths, rgb, metadata], where
                        spim: spectral image cube of form [height, width, bands],
                        wavelengths: the center wavelengths of the bands,
                        rgb: a color render of the spectral image [height, width, channels] or None
                        metadata: a free-form metadata string stored in the image, or an empty string
    """
    TIFFTAG_WAVELENGTHS = 65000
    TIFFTAG_METADATA = 65111
    spim = None
    wavelengths = None
    rgb = None
    metadata = None

    first_band_page = 0
    with TiffFile(filename) as tiff:
        # The RGB image is optional, the first band image maybe on the first page:
        first_band_page = 0
        if tiff.pages[first_band_page].ndim == 3:
            rgb = tiff.pages[0].asarray()
            # Ok, the first band image is on the second page
            first_band_page = first_band_page + 1

        multiple_wavelength_lists = False
        multiple_metadata_fields = False
        for band_page in range(first_band_page, len(tiff.pages)):
            # The wavelength list is supposed to be on the first band image.
            # The older write_tiff writes it on all pages, though, so make
            # a note of it.
            tag = tiff.pages[band_page].tags.get(TIFFTAG_WAVELENGTHS)
            tag_value = tag.value if tag else tuple()
            if tag_value:
                if wavelengths is None:
                    wavelengths = tag_value
                elif wavelengths == tag_value:
                    multiple_wavelength_lists = True
                elif wavelengths != tag_value:
                    # Well, the image is just broken then?
                    raise RuntimeError(f'Spectral-Tiff "{filename}" contains multiple differing wavelength lists!')

            # The metadata string, like the wavelength list, is supposed to be
            # on the first band image. The older write_tiff wrote it on all
            # pages, too. Make a note of it.
            tag = tiff.pages[band_page].tags.get(TIFFTAG_METADATA)
            tag_value = tag.value if tag else ''
            if tag_value:
                if metadata is None:
                    metadata = tag_value
                elif metadata == tag_value:
                    multiple_metadata_fields = True
                elif metadata != tag_value:
                    # Well, for some reason there are multiple metadata fields
                    # with varying content. This version of the function does
                    # not care for such fancyness.
                    raise RuntimeError(f'Spectral-Tiff "{filename}" contains multiple differing metadata fields!')

        # The metadata is stored in an ASCII string. It may contain back-slashed
        # hex sequences (unicode codepoints presented as ASCII text). Convert
        # ASCII string back to bytes and decode as unicode sequence.
        if metadata:
            metadata = metadata.encode('ascii').decode('unicode-escape')
        else:
            metadata = ''

        # Some of the early images may have errorneus metadata string.
        # Attempt to fix it:
        if len(metadata) >= 2 and metadata[0] == "'" and metadata[-1] == "'":
            while metadata[0] == "'":
                metadata = metadata[1:]
            while metadata[-1] == "'":
                metadata = metadata[:-1]
            if '\\n' in metadata:
                metadata = metadata.replace('\\n', '\n')

        # Generate a fake wavelength list, if the spectral tiff has managed to
        # lose its own wavelength list.
        if not wavelengths:
            wavelengths = range(0, len(tiff.pages) - 1 if rgb is not None else len(tiff.pages))

        if multiple_wavelength_lists and not silent:
            warnings.warn(f'Spectral-Tiff "{filename}" contains duplicated wavelength lists!')
        if multiple_metadata_fields and not silent:
            warnings.warn(f'Spectral-Tiff "{filename}" contains duplicated metadata fields!')

        if not rgb_only:
            spim = tiff.asarray(key=range(first_band_page, len(tiff.pages)))
            spim = np.transpose(spim, (1, 2, 0))
        else:
            spim = None

        # Make sure the wavelengths are in an ascending order:
        if wavelengths[0] > wavelengths[-1]:
            spim = spim[:, :, ::-1] if spim is not None else None
            wavelengths = wavelengths[::-1]

    # Convert uint16 cube back to float32 cube
    if spim is not None and spim.dtype == 'uint16':
        spim = spim.astype('float32') / (2**16 - 1)

    return spim, np.array(wavelengths), rgb, metadata

"""# DATASET CREATION FUNCTION"""

def createDataset():
  refimagesnames = os.listdir('drive/MyDrive/Ref 5-7/')
  maskimgs = os.listdir('drive/MyDrive/mask images/')
  removemaskword=[ im.replace('_masks','') for im in maskimgs ]
  all_features_list=[]
  labels_list=['Specular reflection','Artery, ICG','Vein','Stroma, ICG','Artery','Stroma','Suture','Red dye','Umbilical cord','Blue dye','ICG']

  labels_dict={'Specular reflection':0, 'Artery, ICG':1, 'Vein':2, 'Stroma, ICG':3,
                "Artery":4,"Stroma":5,'Suture':6,'Red dye':7,'Umbilical cord':8,'Blue dye':9,"ICG":10}
  
  combined_labels_list=[]
  combined_specs_list=[]
  for i in  range(0,len(refimagesnames)):
    print("File name",refimagesnames[i])

    print("i:::",i)
    if refimagesnames[i] in removemaskword:
      index=removemaskword.index(refimagesnames[i])
      maskimg=maskimgs[index]
      img_read=imread("drive/MyDrive/Ref 5-7/"+refimagesnames[i])
      print('img read',img_read.shape)
      spim, wl, rgb, meta=read_stiff("drive/MyDrive/Ref 5-7/"+refimagesnames[i])
      masks=read_mtiff("drive/MyDrive/mask images/"+maskimg)
      labels=list(masks.keys())
      labels_code_list=[]
      features=[]
      
      for i in range(0,len(labels)):
        n = 10000
        feature=spim[masks[labels[i]],:]

        if n>int(feature.shape[0]):
          # random_artery_spectra
          print("feature shape if",feature.shape[0])
          np.random.shuffle(feature)
          feature=feature[0:n]
          # index = np.random.choice(feature.shape[0], feature.shape[0], replace=False)
        else:
          print("feature shape else",feature.shape[0])
          # index = np.random.shuffle(feature)[0:feature.shape[0]]
          # index = np.random.choice(feature.shape[0], n, replace=False)
          np.random.shuffle(feature)
          feature=feature[0:n]
        
        # feature=feature[index]
        features.append(feature)

        label_index=labels_list.index(labels[i])
        label_name=labels_list[label_index]
        label_code=labels_dict[label_name]

        label=np.ones((feature.shape[0], 1)) * label_code
        # print('feature ',feature)
        # print("label ",label)
        print('feature shape',feature.shape)
        print("label shape",label.shape)
        
        
        labels_code_list.append(label)

      combined_spectra_image=np.vstack(features)
      combined_label_image=np.vstack(labels_code_list)
    

      combined_specs_list.append(combined_spectra_image)
      combined_labels_list.append(combined_label_image)



  # print("combined_specs_list",combined_specs_list)
  # print("combined_labels_list",combined_labels_list)


  combined_spectra=np.vstack(combined_specs_list)
  combined_labels=np.vstack(combined_labels_list)

  print("______________________________________________")
  print("combined_spectra shape",combined_spectra.shape)
  print("combined_labels shape",combined_labels.shape)

  # print("combined_spectra",combined_spectra)
  # print("combined_labels",combined_labels)
  return combined_spectra,combined_labels

combined_spectra,combined_labels=createDataset()

"""# Save & Read dataset"""

# Write Features and labels into data.h5 and create it. 
hf = h5py.File('kbest20_mlp10000_dataset.h5', 'w')
hf.create_dataset('features', data=combined_spectra)
hf.create_dataset('labels', data=combined_labels)
hf.close()

#Reading h5py file
hf = h5py.File('kbest20_mlp10000_dataset.h5', 'r')
hf.keys()
# extract features
features = hf.get('features')
labels = hf.get('labels')
features = np.array(features)
labels = np.array(labels)

"""# Feature Selection"""

X=combined_spectra
y=combined_labels

y=y.astype(int)
y=y.ravel()


selectorKb = SelectKBest(chi2, k=35).fit(X, y)
X_pruned = selectorKb.transform(X)
X_pruned.shape
# filename = 'kbest35_n10000.joblib'
# dump(selectorKb, filename)

"""# Splitting of Dataset"""

sss = StratifiedShuffleSplit(n_splits=5, test_size=0.5, random_state=0)
for train_index, test_index in sss.split(X_pruned, y):
    print("TRAIN:", train_index, "TEST:", test_index)
    X_train, X_test = X_pruned[train_index], X_pruned[test_index]
    y_train, y_test = y[train_index], y[test_index]
# Training and Testing Dataset Creation
dataset=h5py.File('kbest35_mlp10000_datasetlogistic.h5', 'w')
dataset.create_dataset('trainx', data=X_train)
dataset.create_dataset('trainy', data=y_train)
dataset.create_dataset('testx', data=X_test)
dataset.create_dataset('testy', data=y_test)
dataset.close()

"""# Classification Process
Training Method (Models)

SAVING The Model code
"""

#SAVING the MODEL CODE
filename = 'kbest35_mlp10000logistic.joblib'
dump(clf, filename)
# clf=load('kbest35_mlp10000.joblib')

"""MLP CLASSFIER"""


clf = MLPClassifier(random_state=0, max_iter=300,activation='logistic',
                    early_stopping=True).fit(X_train, y_train)

print(clf.score(X_train, y_train))

"""KNN Classifier"""

knn = KNeighborsClassifier(n_neighbors=10,weights='distance',n_jobs=-1)
knnclf = Pipeline([ ('knn', knn)])
knnclf.fit(X_train, y_train)
print(knnclf.score(X_test, y_test))

"""Gaussian Naive Bayes"""

gnb = GaussianNB()
gnb.fit(X_train, y_train)
gnb.score(X_test, y_test)

"""Logistic Regression """

lgr=LogisticRegression()
lgr.fit(X_train, y_train)
lgr.score(X_test,y_test)
# score=cross_val_score(pcr, X, y, cv=5)

"""SVM Multi Classifier"""

clf = svm.SVC(decision_function_shape='ovo')
clf.fit(X_train, y_train)
clf.score(X_test,y_test)

"""Random Forrest Classifier"""

clf = RandomForestClassifier(max_depth=5, random_state=0)
clf.fit(X_train, y_train)
clf.score(X_test,y_test)

"""Radius Neighbors Classifier"""

RadiusNeighborsClassifier(radius=1.0, 
                          weights='uniform', 
                          algorithm='auto', 
                          leaf_size=30, p=2, 
                          metric='minkowski', outlier_label=None, 
                          metric_params=None, n_jobs=None)

"""KMEANS CLUSTERING"""

kmclf = KMeans(n_clusters=10, random_state=0,precompute_distances=True).fit(X_train)
print("X_train subset",X_train[0:100])
kmclf.transform(X_train)
print("X train after transform",X_train[0:100])
print("Score",kmclf.score(X_test))

"""Decision Tree Classifier"""

clf=tree.DecisionTreeClassifier()
clf.fit(X_train, y_train)
score = clf.score(X_test, y_test)
print("score",score)

"""# PRIDICTION PART

General Prediction Code
"""

def predictFunction(modelobj,selectorKb):
  spim, wl, colorimg, meta=read_stiff("drive/MyDrive/Ref 5-7/lower_5_icg.tif")
  new_img = spim.reshape((spim.shape[0]*spim.shape[1]), spim.shape[2]) # (H*W,b)
  print(new_img.shape)
  xtest1=selectorKb.transform(new_img)
  print(xtest1.shape)
  prediction=modelobj.predict(xtest1)
  prediction=prediction.astype(int)
  print("prediction shpare",prediction.shape)
  unique_labels_testingimage=np.unique(prediction)
  label_img = np.reshape(prediction, (spim.shape[0], spim.shape[1]))
  label_img.shape
  return label_img,prediction

"""MLP Classifier Prediction Code"""

label_img,prediction=predictFunction(clf,selectorKb)

"""KNN Classifier Prediction Code"""

label_img,prediction=predictFunction(knnclf,selectorKb)

"""Gausian Prediction Code"""

label_img,prediction=predictFunction(gnb,selectorKb)

"""SVM Prediction Code"""

label_img,prediction=predictFunction(clf,selectorKb)

"""Random Forrest Prediction Code"""

label_img,prediction=predictFunction(clf,selectorKb)

"""K means Clustering Unsupervised"""

label_img,prediction=predictFunction(kmclf,selectorKb)

"""Decision Tree Classifier"""

label_img,prediction=predictFunction(clf,selectorKb)

"""True, False, Posivtive and Negative Calculation Function"""

# Copied
def perf_measure(y_actual, y_pred):
    TP = 0
    FP = 0
    TN = 0
    FN = 0

    for i in range(len(y_pred)): 
        if y_actual[i]==y_pred[i]==1:
           TP += 1
        if y_pred[i]==1 and y_actual[i]!=y_pred[i]:
           FP += 1
        if y_actual[i]==y_pred[i]==0:
           TN += 1
        if y_pred[i]==0 and y_actual[i]!=y_pred[i]:
           FN += 1
    return TP,FP,TN,FN

"""# EVALUATIONS

General Confusion Matrix Function
"""

def confMat(modelObj,y_test,X_test):
  prediction_xtest=modelObj.predict(X_test)

  y_test=y_test.astype(int)
  prediction_xtest=prediction_xtest.astype(int)
  labels_list=['Specular reflection','Artery, ICG','Vein','Stroma, ICG','Artery','Stroma','Suture','Red dye','Umbilical cord','Blue dye','ICG']


  cm =confusion_matrix(y_test, prediction_xtest)

  disp=plot_confusion_matrix(modelObj, X_test, y_test,
                                 display_labels=['SpR','AIG',"V",'StIG','A','St','Su','RD','UC','BD','IG'],
                                 cmap=plt.cm.Blues,
                                )

  print(disp.confusion_matrix)
  
  plt.show()
  TP, FP, TN, FN=perf_measure(y_test,prediction_xtest)
  accuracy=(TP+TN)/(TP+FP+TN+FN)
  sensitivity= (TP)/(TP+FN)
  specificity= (TN)/(TN+FP)

  fpr=1-specificity
  print("accuracy",accuracy)
  print("sensitivity",sensitivity)
  print("specificity",specificity)

"""Confusion Matrix Of Algorithm MLP"""

confMat(clf,y_test,X_test)

"""KNN Confusion Matrix"""

# for knn
confMat(knnclf,y_test,X_test)

"""Gaussian Confusion Matrix"""

confMat(gnb,y_test,X_test)

"""Random Forrest Consfusion Matrix"""

confMat(clf,y_test,X_test)

"""KMeans Clusstering"""

confMat(kmclf,y_test,X_test)

"""DecisionTree ConfMat"""

confMat(clf,y_test,X_test)

"""# VISUALIZATION

Display Prediction on image.
"""


spim, wl, colorimg, meta=read_stiff("drive/MyDrive/Ref 5-7/lower_5_icg.tif")
new_img = spim.reshape((spim.shape[0]*spim.shape[1]), spim.shape[2]) # (H*W,b)
image=spim[:,:,0]
thresholded_image = image > 0.05
fig, axs = plt.subplots(nrows=1, ncols=1)
axs.imshow(thresholded_image,'gray')
plt.show()


label_image = label(thresholded_image)
print(label_image.shape)  
props = regionprops(label_image)
# red,gray,green,black,purple,blue,yellow,aqua,brown,magenta,orange
color_dict={0:[255,0,0],1:[128,128,128],2:[0,128,0],3:[0,0,0],4:[128,0,128],5:[0,0,255],6:[255,255,0],7:[0,100,100],
            8:[165,42,42],9:[255,0,255],10:[255,165,0]}

for p in props:
  region_coords=p.coords
  for pixelcoord in  region_coords:
    colorimg[pixelcoord[1],pixelcoord[0]]=color_dict[label_img[pixelcoord[1],pixelcoord[0]]]

  
fig, ax = plt.subplots(figsize=(10, 6))
ax.imshow(colorimg)
# plt.savefig("decisiontreeN1000k3")